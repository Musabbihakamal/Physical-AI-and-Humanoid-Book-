"""
Glossary service for the multi-agent book generation system.
"""
from sqlalchemy.orm import Session
from typing import List, Dict, Any, Optional
from hashlib import sha256
from ..models.generated_content import GeneratedContent
from ..models.content_link import ContentLink
from ..utils.content_formatter import extract_terms_from_content
from ..utils import agent_cache, get_cache_key
import logging
import json

logger = logging.getLogger(__name__)


class GlossaryService:
    @staticmethod
    async def generate_glossary(
        db: Session,
        content: str,
        request_id: str,
        user_profile: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Generate a glossary from the provided content.

        Args:
            db: Database session
            content: The content to extract terms from
            request_id: The ID of the agent request
            user_profile: Optional user profile for personalization

        Returns:
            Dictionary containing the generated glossary
        """
        try:
            # Generate cache key based on content and user profile
            content_hash = sha256(content.encode()).hexdigest()
            user_id = user_profile.get("user_id") if user_profile else None
            cache_key = get_cache_key("glossary", content_hash, user_id)

            # Try to get from cache first
            cached_result = agent_cache.get(cache_key)
            if cached_result:
                logger.info("Glossary retrieved from cache")
                return cached_result

            # Extract potential terms from the content
            potential_terms = extract_terms_from_content(content)

            # Create a basic glossary structure
            glossary_entries = []

            # For each potential term, create a basic definition
            # In a real implementation, this would call an LLM to generate proper definitions
            for term in potential_terms[:20]:  # Limit to top 20 terms for performance
                # Create a basic definition (in real implementation, this would be generated by an agent)
                definition = f"A definition for {term} would be generated here based on context."

                # Add the entry to the glossary
                glossary_entries.append({
                    "term": term,
                    "definition": definition,
                    "examples": [],
                    "related_terms": []
                })

            # Create the glossary content
            glossary_content = {
                "title": "Generated Glossary",
                "entries": glossary_entries,
                "source_content_length": len(content),
                "terms_count": len(glossary_entries)
            }

            # Save the generated content to the database
            generated_content = GeneratedContent(
                request_id=request_id,
                content_type="GLOSSARY",
                content=json.dumps(glossary_content),
                metadata={
                    "source_content_length": len(content),
                    "terms_extracted": len(potential_terms),
                    "terms_included": len(glossary_entries)
                },
                quality_score="75"  # Default quality score
            )

            db.add(generated_content)
            db.commit()
            db.refresh(generated_content)

            logger.info(f"Glossary generated with ID: {generated_content.id}")

            result = {
                "id": str(generated_content.id),
                "content_type": "GLOSSARY",
                "glossary": glossary_content,
                "quality_score": 75
            }

            # Cache the result for 10 minutes (600 seconds) if not personalized
            if not user_id:
                agent_cache.set(cache_key, result, ttl=600)

            return result

        except Exception as e:
            logger.error(f"Error generating glossary: {str(e)}", exc_info=True)
            raise

    @staticmethod
    async def term_extraction(content: str) -> List[str]:
        """
        Extract terms from content using pattern recognition.

        Args:
            content: The content to extract terms from

        Returns:
            List of extracted terms
        """
        try:
            # Use the utility function to extract terms
            terms = extract_terms_from_content(content)

            logger.info(f"Extracted {len(terms)} terms from content")
            return terms

        except Exception as e:
            logger.error(f"Error extracting terms: {str(e)}", exc_info=True)
            raise

    @staticmethod
    async def term_definition_generation(terms: List[str], content_context: str) -> Dict[str, str]:
        """
        Generate definitions for the provided terms based on content context.

        Args:
            terms: List of terms to define
            content_context: The content context for generating definitions

        Returns:
            Dictionary mapping terms to their definitions
        """
        try:
            definitions = {}

            # In a real implementation, this would call an LLM to generate proper definitions
            for term in terms:
                # Create a basic definition (in real implementation, this would be generated by an agent)
                definition = f"Definition for '{term}' based on the provided context would be generated here."
                definitions[term] = definition

            logger.info(f"Generated definitions for {len(definitions)} terms")
            return definitions

        except Exception as e:
            logger.error(f"Error generating term definitions: {str(e)}", exc_info=True)
            raise